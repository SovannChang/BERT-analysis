{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1879363",
   "metadata": {},
   "source": [
    "This document is a demonstration of the BERT model, retrieved from https://huggingface.co/bert-base-cased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe02dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the line below to install the transformers package\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fb5977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf0d56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Import BERT (cased)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = BertForNextSentencePrediction.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Pre-built for masking tasks\n",
    "unmasker = pipeline('fill-mask', model='bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504c7fd",
   "metadata": {},
   "source": [
    "Testing the \"unmasker\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89372b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well                      0.683454\n",
      "effectively               0.079846\n",
      "efficiently               0.036923\n",
      "far                       0.014120\n",
      "accurately                0.013984\n"
     ]
    }
   ],
   "source": [
    "for dictionary in unmasker(\"This is a test of how [MASK] the model works\"):\n",
    "    print(\"{:<25s} {:f}\".format(dictionary.get(\"token_str\"), dictionary.get(\"score\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af28324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alternative               0.079788\n",
      "other                     0.066093\n",
      "obvious                   0.056552\n",
      "clear                     0.044919\n",
      "possible                  0.040370\n"
     ]
    }
   ],
   "source": [
    "for dictionary in unmasker(\"This is a more ambiguous answer. There is no [MASK] solution\"):\n",
    "    print(\"{:<25s} {:f}\".format(dictionary.get(\"token_str\"), dictionary.get(\"score\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b775fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",                         0.116117\n",
      "and                       0.051120\n",
      ":                         0.041306\n",
      "-                         0.040721\n",
      "of                        0.022506\n"
     ]
    }
   ],
   "source": [
    "for dictionary in unmasker(\"Gibberish: cardboard indigo dog outer [MASK] turpentine France shellack\"):\n",
    "    print(\"{:<25s} {:f}\".format(dictionary.get(\"token_str\"), dictionary.get(\"score\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05308452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bert_nsp(first_sentence, possible_next_sentence):\n",
    "    encoding = tokenizer(first_sentence, possible_next_sentence, return_tensors=\"pt\")\n",
    "    logits = model(**encoding, labels=torch.LongTensor([1])).logits    # logits are output\n",
    "    \n",
    "    probs = softmax(logits, dim=1)\n",
    "    \n",
    "    print(probs[0,0].item())\n",
    "    \n",
    "    if probs[0,0] < probs[0,1]:\n",
    "        print(\"Not likely to be the next sentence.\")\n",
    "    else:\n",
    "        print(\"Likely to be the next sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976216b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9972876310348511\n",
      "Likely to be the next sentence.\n"
     ]
    }
   ],
   "source": [
    "run_bert_nsp(\"Folk in those stories had lots of chances of turning back, only they didn't.\", \n",
    "             \"They kept going because they were holding onto something.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9540a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13158494234085083\n",
      "Not likely to be the next sentence.\n"
     ]
    }
   ],
   "source": [
    "run_bert_nsp(\"Tell him about the Twinkie.\", \n",
    "             \"Are you telling me you built a time machine out of a DeLorean?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7943fec",
   "metadata": {},
   "source": [
    "This behavior is as expected. It makes sense so far. But then, it gets weird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb7f976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6591819524765015\n",
      "Likely to be the next sentence.\n"
     ]
    }
   ],
   "source": [
    "run_bert_nsp(\"I don't like sand.\", \n",
    "             \"You're my favorite deputy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6753613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9073694348335266\n",
      "Likely to be the next sentence.\n"
     ]
    }
   ],
   "source": [
    "run_bert_nsp(\"I don't like sand\", \n",
    "             \"You're my favorite deputy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8176429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9806997776031494\n",
      "Likely to be the next sentence.\n"
     ]
    }
   ],
   "source": [
    "run_bert_nsp(\"It's over, Anakin!\", \n",
    "             \"I have the high ground.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b21b0",
   "metadata": {},
   "source": [
    "I wanted to find a sentence where the model was as close to uncertain as possible. This was the closest I could come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2acdd840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4564545452594757\n",
      "Not likely to be the next sentence.\n"
     ]
    }
   ],
   "source": [
    "run_bert_nsp(\"The waves crashed against the shore, leaving a line of foam in their wake.\", \n",
    "             \"The painter applied the final brushstrokes to the canvas, completing the masterpiece.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
